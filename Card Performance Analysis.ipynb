{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd44d08-12c1-4e84-8cc7-67cb63a3ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "folder_path = 'My Files'\n",
    "\n",
    "# File to keep track of processed files\n",
    "processed_files_log = 'processed_files.txt'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "df_list = []\n",
    "\n",
    "# Check if the log file exists, if not, create an empty one\n",
    "if not os.path.exists(processed_files_log):\n",
    "    with open(processed_files_log, 'w') as log_file:\n",
    "        log_file.write('')  # Create an empty file\n",
    "\n",
    "# Read the log file to get the list of processed files\n",
    "with open(processed_files_log, 'r') as log_file:\n",
    "    processed_files = log_file.read().splitlines()\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a CSV file and has not been processed before\n",
    "    if filename not in processed_files:\n",
    "        # Create the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            # Read the CSV file into a dataframe\n",
    "            df = pd.read_csv(file_path, low_memory=False, encoding='latin1', on_bad_lines='skip')\n",
    "            # Check if the dataframe is not empty\n",
    "            if not df.empty:\n",
    "                # Append the dataframe to the list\n",
    "                df_list.append(df)\n",
    "                # Add the filename to the processed files list\n",
    "                processed_files.append(filename)\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Check if the list of dataframes is not empty\n",
    "if df_list:\n",
    "    # Concatenate all dataframes in the list into a single dataframe\n",
    "    new_data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Load the existing combined DataFrame if it exists\n",
    "    if 'combined_df' in locals():  # Check if combined_df exists from previous runs\n",
    "        combined_df = pd.concat([combined_df, new_data], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = new_data\n",
    "\n",
    "    # Display the first few rows of the combined dataframe\n",
    "    print(combined_df.head())\n",
    "\n",
    "    # Update the log file with the newly processed files\n",
    "    with open(processed_files_log, 'w') as log_file:\n",
    "        log_file.write('\\n'.join(processed_files))\n",
    "else:\n",
    "    print(\"No new CSV files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd1152-7886-4291-b194-877ddece225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of 'combined_df' to work with\n",
    "df = combined_df.copy()\n",
    "\n",
    "# Remove duplicate rows based on the 'Transaction ID' column\n",
    "df = df.drop_duplicates(subset='Transaction ID')\n",
    "\n",
    "# Convert the 'Date' column to datetime format, specifying the format of the date string\n",
    "# Handle parsing errors by converting invalid parsing to NaT (Not a Time)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%y %H.%M.%S', errors='coerce')\n",
    "\n",
    "# Extract the month name from the 'Date' column and create a new column 'Month Name'\n",
    "df['Month Name'] = df['Date'].dt.month_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c225d-f574-458d-9afc-822a2889836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a new column 'BIN' by extracting the first 6 characters from the 'PAN ' column\n",
    "df['BIN'] = df['PAN '].str[:6]\n",
    "\n",
    "# Create a new column 'Card Type' based on the 'BIN' values\n",
    "# Use np.where to classify 'BIN' into 'Debit', 'Prepaid', or 'Credit'\n",
    "df['Card Type'] = np.where(\n",
    "    df['BIN'].isin(['000111', '000222', '000333', '000444']), 'Debit', \n",
    "    np.where(\n",
    "        df['BIN'].isin(['111000', '111222', '111333']), 'Prepaid', \n",
    "        'Credit'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa38cd-6e70-4bbb-a3bd-70a93d17c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by 'Month Name' and 'Response code', then count the occurrences\n",
    "grouped = grouped.groupby(['Month Name', 'Response code']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot the table to get 'Month Name' as index, 'Response code' as columns, and 'Count' as values\n",
    "# Fill missing values with 0 and transpose the table\n",
    "pivot = grouped.pivot_table(index='Month Name', columns='Response code', values='Count', fill_value=0).T\n",
    "\n",
    "# Calculate the total count for each response code across all months\n",
    "total_counts = pivot.sum(axis=0)\n",
    "\n",
    "# Calculate the percentage for each response code within each month\n",
    "pivot_percentage = (pivot.divide(total_counts, axis=1) * 100)\n",
    "\n",
    "# Create a copy of pivot_percentage to sort by each month\n",
    "sorted_combined = pivot_percentage.copy()\n",
    "\n",
    "# Iterate over each month column to sort the data by response code percentages in descending order\n",
    "for month in sorted_combined.columns:\n",
    "    sorted_combined = sorted_combined.sort_values(by=(month), ascending=False)\n",
    "\n",
    "# Display the sorted data\n",
    "sorted_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff03b9-eda5-4129-99c7-c5f9251e42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors for specific response codes\n",
    "custom_colors = {\n",
    "    '00 - approved': '#008000',\n",
    "    '51-Insufficient funds': '#FF0000',# Example color for \"51-Insufficient funds\"\n",
    "    # Add more response codes and colors if needed\n",
    "}\n",
    "\n",
    "# Remove duplicates and filter for September\n",
    "grouped = df.drop_duplicates(subset='Transaction ID')\n",
    "grouped = grouped[grouped['Month Name'] == 'September']\n",
    "\n",
    "# Group by 'Card Type' and 'Response code'\n",
    "grouped = grouped.groupby(['Card Type', 'Response code']).size().reset_index(name='Count')\n",
    "\n",
    "# Calculate total counts per card type\n",
    "total_counts = grouped.groupby('Card Type')['Count'].transform('sum')\n",
    "\n",
    "# Calculate percentages of each response code per card type\n",
    "grouped['Percentage'] = (grouped['Count'] / total_counts) * 100\n",
    "\n",
    "# Filter out '00 - approved' and find the top 5 response codes per card type\n",
    "# top_5 = grouped[grouped['Response code'] != '00 - approved']\n",
    "top_5 = grouped.groupby('Card Type').apply(lambda x: x.nlargest(5, 'Percentage')).reset_index(drop=True)\n",
    "\n",
    "# Loop through each Card Type and plot the top 5 response codes for that card type\n",
    "for card_type in top_5['Card Type'].unique():\n",
    "    # Filter the data for the current card type\n",
    "    card_type_data = top_5[top_5['Card Type'] == card_type]\n",
    "\n",
    "     # Create a list of colors based on the response code\n",
    "    bar_colors = [custom_colors.get(rc, '#808080') for rc in card_type_data['Response code']]  # Default to gray if not specified\n",
    "        \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    ax = sns.barplot(x='Response code', y='Percentage', hue='Response code', data=card_type_data, palette=bar_colors, legend=False)\n",
    "    \n",
    "    # Rotate the x-axis labels to avoid clustering\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate labels and align to the right\n",
    "\n",
    "    # Extend y-axis limits to provide space for labels\n",
    "    #plt.ylim(0, top_5['Percentage'].max() * 1.1)  # Add 20% space above the highest bar\n",
    "\n",
    "    # Add percentage labels on top of the bars\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(f'{height:.2f}%', \n",
    "                    (p.get_x() + p.get_width() / 2., height), \n",
    "                    ha='center', va='bottom', \n",
    "                    xytext=(0, 3), textcoords='offset points', fontsize=10, color='black')\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title(f'Top 5 Response Codes for {card_type}')\n",
    "    plt.xlabel('Response Code')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
